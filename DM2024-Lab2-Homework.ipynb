{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: è”¡æœ¨é¢¨\n",
    "\n",
    "Student ID: 113062628\n",
    "\n",
    "GitHub ID: Arya0309\n",
    "\n",
    "Kaggle name: Chua_Arya\n",
    "\n",
    "Kaggle private scoreboard snapshot:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home exercises** in the [DM2024-Lab2-master Repo](https://github.com/didiersalazar/DM2024-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework) regarding Emotion Recognition on Twitter by this link: https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)**. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developing the model for the competition (You can use code and comment on it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Enviroment build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "balance = False\n",
    "val = False  # Split validation of not\n",
    "val_size = 0.1\n",
    "lr = 2e-5\n",
    "batch_size = 64\n",
    "epochs = 8\n",
    "warmup_proportion = 0.1\n",
    "patience = 3\n",
    "grad_clip = 1.0\n",
    "lora = False\n",
    "weighted_loss = False\n",
    "model_name = \"FacebookAI/roberta-large\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweet': {'hashtags': ['Snapchat'],\n",
       "  'tweet_id': '0x376b20',\n",
       "  'text': 'People who post \"add me on #Snapchat\" must be dehydrated. Cuz man.... that\\'s <LH>'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_path = \"dataset/\"\n",
    "df_data = pd.read_json(os.path.join(data_path, \"tweets_DM.json\"), lines=True)\n",
    "df_data[\"_source\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>_index</th>\n",
       "      <th>_source</th>\n",
       "      <th>_crawldate</th>\n",
       "      <th>_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['Snapchat'], 'tweet_id...</td>\n",
       "      <td>2015-05-23 11:42:47</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['freepress', 'TrumpLeg...</td>\n",
       "      <td>2016-01-28 04:52:09</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['bibleverse'], 'tweet_...</td>\n",
       "      <td>2017-12-25 04:39:20</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>376</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...</td>\n",
       "      <td>2016-01-24 23:53:05</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>989</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x2de2...</td>\n",
       "      <td>2016-01-08 17:18:59</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _score          _index                                            _source  \\\n",
       "0     391  hashtag_tweets  {'tweet': {'hashtags': ['Snapchat'], 'tweet_id...   \n",
       "1     433  hashtag_tweets  {'tweet': {'hashtags': ['freepress', 'TrumpLeg...   \n",
       "2     232  hashtag_tweets  {'tweet': {'hashtags': ['bibleverse'], 'tweet_...   \n",
       "3     376  hashtag_tweets  {'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...   \n",
       "4     989  hashtag_tweets  {'tweet': {'hashtags': [], 'tweet_id': '0x2de2...   \n",
       "\n",
       "            _crawldate   _type  \n",
       "0  2015-05-23 11:42:47  tweets  \n",
       "1  2016-01-28 04:52:09  tweets  \n",
       "2  2017-12-25 04:39:20  tweets  \n",
       "3  2016-01-24 23:53:05  tweets  \n",
       "4  2016-01-08 17:18:59  tweets  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source = pd.json_normalize(df_data[\"_source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet.hashtags</th>\n",
       "      <th>tweet.tweet_id</th>\n",
       "      <th>tweet.text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  tweet.hashtags tweet.tweet_id  \\\n",
       "0                     [Snapchat]       0x376b20   \n",
       "1  [freepress, TrumpLegacy, CNN]       0x2d5350   \n",
       "2                   [bibleverse]       0x28b412   \n",
       "3                             []       0x1cd5b0   \n",
       "4                             []       0x2de201   \n",
       "\n",
       "                                          tweet.text  \n",
       "0  People who post \"add me on #Snapchat\" must be ...  \n",
       "1  @brianklaas As we see, Trump is dangerous to #...  \n",
       "2  Confident of your obedience, I write to you, k...  \n",
       "3                Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ <LH>  \n",
       "4  \"Trust is not the same as faith. A friend is s...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_source.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.concat([df_data, df_source], axis=1)\n",
    "df_data = df_data.drop(columns=[\"_source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>_index</th>\n",
       "      <th>_crawldate</th>\n",
       "      <th>_type</th>\n",
       "      <th>tweet.hashtags</th>\n",
       "      <th>tweet.tweet_id</th>\n",
       "      <th>tweet.text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>2015-05-23 11:42:47</td>\n",
       "      <td>tweets</td>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>2016-01-28 04:52:09</td>\n",
       "      <td>tweets</td>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>2017-12-25 04:39:20</td>\n",
       "      <td>tweets</td>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>376</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>2016-01-24 23:53:05</td>\n",
       "      <td>tweets</td>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>989</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>2016-01-08 17:18:59</td>\n",
       "      <td>tweets</td>\n",
       "      <td>[]</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _score          _index           _crawldate   _type  \\\n",
       "0     391  hashtag_tweets  2015-05-23 11:42:47  tweets   \n",
       "1     433  hashtag_tweets  2016-01-28 04:52:09  tweets   \n",
       "2     232  hashtag_tweets  2017-12-25 04:39:20  tweets   \n",
       "3     376  hashtag_tweets  2016-01-24 23:53:05  tweets   \n",
       "4     989  hashtag_tweets  2016-01-08 17:18:59  tweets   \n",
       "\n",
       "                  tweet.hashtags tweet.tweet_id  \\\n",
       "0                     [Snapchat]       0x376b20   \n",
       "1  [freepress, TrumpLegacy, CNN]       0x2d5350   \n",
       "2                   [bibleverse]       0x28b412   \n",
       "3                             []       0x1cd5b0   \n",
       "4                             []       0x2de201   \n",
       "\n",
       "                                          tweet.text  \n",
       "0  People who post \"add me on #Snapchat\" must be ...  \n",
       "1  @brianklaas As we see, Trump is dangerous to #...  \n",
       "2  Confident of your obedience, I write to you, k...  \n",
       "3                Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ <LH>  \n",
       "4  \"Trust is not the same as faith. A friend is s...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data.rename(columns={\"tweet.tweet_id\": \"tweet_id\"})\n",
    "df_data = df_data.rename(columns={\"tweet.text\": \"text\"})\n",
    "df_data = df_data.rename(columns={\"_score\": \"score\"})\n",
    "df_data.drop(\n",
    "    columns={\"_type\", \"tweet.hashtags\", \"_index\", \"_crawldate\"},\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>376</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>989</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score  tweet_id                                               text\n",
       "0    391  0x376b20  People who post \"add me on #Snapchat\" must be ...\n",
       "1    433  0x2d5350  @brianklaas As we see, Trump is dangerous to #...\n",
       "2    232  0x28b412  Confident of your obedience, I write to you, k...\n",
       "3    376  0x1cd5b0                Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ <LH>\n",
       "4    989  0x2de201  \"Trust is not the same as faith. A friend is s..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_identification = pd.read_csv(os.path.join(data_path, \"data_identification.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.merge(df_data, df_identification, on=\"tweet_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>376</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>989</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score  tweet_id                                               text  \\\n",
       "0    391  0x376b20  People who post \"add me on #Snapchat\" must be ...   \n",
       "1    433  0x2d5350  @brianklaas As we see, Trump is dangerous to #...   \n",
       "2    232  0x28b412  Confident of your obedience, I write to you, k...   \n",
       "3    376  0x1cd5b0                Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ <LH>   \n",
       "4    989  0x2de201  \"Trust is not the same as faith. A friend is s...   \n",
       "\n",
       "  identification  \n",
       "0          train  \n",
       "1          train  \n",
       "2           test  \n",
       "3          train  \n",
       "4           test  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_data[df_data[\"identification\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotion = pd.read_csv(os.path.join(data_path, \"emotion.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x3140b1</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x368b73</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x296183</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2bd6e1</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2ee1dd</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id       emotion\n",
       "0  0x3140b1       sadness\n",
       "1  0x368b73       disgust\n",
       "2  0x296183  anticipation\n",
       "3  0x2bd6e1           joy\n",
       "4  0x2ee1dd  anticipation"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emotion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.merge(df_data, df_emotion, on=\"tweet_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>376</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>0x1d755c</td>\n",
       "      <td>@RISKshow @TheKevinAllison Thx for the BEST TI...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1021</td>\n",
       "      <td>0x2c91a8</td>\n",
       "      <td>Still waiting on those supplies Liscus. &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score  tweet_id                                               text  \\\n",
       "0    391  0x376b20  People who post \"add me on #Snapchat\" must be ...   \n",
       "1    433  0x2d5350  @brianklaas As we see, Trump is dangerous to #...   \n",
       "2    376  0x1cd5b0                Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ <LH>   \n",
       "3    120  0x1d755c  @RISKshow @TheKevinAllison Thx for the BEST TI...   \n",
       "4   1021  0x2c91a8       Still waiting on those supplies Liscus. <LH>   \n",
       "\n",
       "  identification       emotion  \n",
       "0          train  anticipation  \n",
       "1          train       sadness  \n",
       "2          train          fear  \n",
       "3          train           joy  \n",
       "4          train  anticipation  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_data[df_data[\"identification\"] == \"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>376</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>0x1d755c</td>\n",
       "      <td>@RISKshow @TheKevinAllison Thx for the BEST TI...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1021</td>\n",
       "      <td>0x2c91a8</td>\n",
       "      <td>Still waiting on those supplies Liscus. &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score  tweet_id                                               text  \\\n",
       "0    391  0x376b20  People who post \"add me on #Snapchat\" must be ...   \n",
       "1    433  0x2d5350  @brianklaas As we see, Trump is dangerous to #...   \n",
       "2    376  0x1cd5b0                Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ <LH>   \n",
       "3    120  0x1d755c  @RISKshow @TheKevinAllison Thx for the BEST TI...   \n",
       "4   1021  0x2c91a8       Still waiting on those supplies Liscus. <LH>   \n",
       "\n",
       "  identification       emotion  \n",
       "0          train  anticipation  \n",
       "1          train       sadness  \n",
       "2          train          fear  \n",
       "3          train           joy  \n",
       "4          train  anticipation  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>989</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>66</td>\n",
       "      <td>0x218443</td>\n",
       "      <td>When do you have enough ? When are you satisfi...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>104</td>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>God woke you up, now chase the day #GodsPlan #...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>310</td>\n",
       "      <td>0x26289a</td>\n",
       "      <td>In these tough times, who do YOU turn to as yo...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    score  tweet_id                                               text  \\\n",
       "2     232  0x28b412  Confident of your obedience, I write to you, k...   \n",
       "4     989  0x2de201  \"Trust is not the same as faith. A friend is s...   \n",
       "9      66  0x218443  When do you have enough ? When are you satisfi...   \n",
       "30    104  0x2939d5  God woke you up, now chase the day #GodsPlan #...   \n",
       "33    310  0x26289a  In these tough times, who do YOU turn to as yo...   \n",
       "\n",
       "   identification  \n",
       "2            test  \n",
       "4            test  \n",
       "9            test  \n",
       "30           test  \n",
       "33           test  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411972"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411972"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.reset_index(drop=True, inplace=True)\n",
    "len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(3785)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"text\"].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop_duplicates(subset=\"text\", keep=\"first\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"text\"].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_distribution(df, column=\"emotion\"):\n",
    "    datas = df.groupby(column).size()\n",
    "    ax = datas.plot(kind=\"bar\", legend=False)\n",
    "\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(\n",
    "            f\"{p.get_height()}\",\n",
    "            (p.get_x() + p.get_width() / 2.0, p.get_height()),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            xytext=(0, 5),\n",
    "            textcoords=\"offset points\",\n",
    "        )\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_distribution(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if val:  # Split validation if needed\n",
    "    df_val = df_train.sample(frac=val_size, random_state=seed)\n",
    "    df_train = df_train.drop(df_val.index)\n",
    "\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_val = df_val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df_train[df_train[\"emotion\"] != \"joy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pandas as pd\n",
    "\n",
    "if balance:\n",
    "    X = df_train[\"text\"]\n",
    "    y = df_train[\"emotion\"]\n",
    "\n",
    "    upper_bound = 300000\n",
    "    lower_bound = 0\n",
    "\n",
    "    oversample_strategy = {}\n",
    "    for label in y.unique():\n",
    "        current_count = (y == label).sum()\n",
    "        if current_count < lower_bound:\n",
    "            oversample_strategy[label] = lower_bound\n",
    "        else:\n",
    "            oversample_strategy[label] = current_count\n",
    "\n",
    "    oversampler = RandomOverSampler(\n",
    "        sampling_strategy=oversample_strategy, random_state=seed\n",
    "    )\n",
    "    X_oversampled, y_oversampled = oversampler.fit_resample(X.to_frame(), y)\n",
    "\n",
    "    df_oversampled = pd.concat([X_oversampled, y_oversampled], axis=1)\n",
    "    df_oversampled.columns = [\"text\", \"emotion\"]\n",
    "\n",
    "    undersample_strategy = {}\n",
    "    for label in df_oversampled[\"emotion\"].unique():\n",
    "        current_count = (df_oversampled[\"emotion\"] == label).sum()\n",
    "        if current_count > upper_bound:\n",
    "            undersample_strategy[label] = 96971\n",
    "        else:\n",
    "            undersample_strategy[label] = current_count\n",
    "\n",
    "    undersampler = RandomUnderSampler(\n",
    "        sampling_strategy=undersample_strategy, random_state=seed\n",
    "    )\n",
    "    X_balanced, y_balanced = undersampler.fit_resample(\n",
    "        df_oversampled[[\"text\"]], df_oversampled[\"emotion\"]\n",
    "    )\n",
    "\n",
    "    # Step 4: Create the final resampled DataFrame\n",
    "    df_balanced = pd.concat([X_balanced, y_balanced], axis=1)\n",
    "    df_balanced.columns = [\"text\", \"emotion\"]\n",
    "\n",
    "    # Step 5: Verify the new distribution\n",
    "    print(df_balanced[\"emotion\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if balance:\n",
    "    df_train = df_balanced\n",
    "    plot_distribution(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3447/645112662.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_sample = df_train.groupby(\"emotion\", group_keys=False).apply(lambda x: x.sample(n=7))\n"
     ]
    }
   ],
   "source": [
    "df_sample = df_train.groupby(\"emotion\", group_keys=False).apply(lambda x: x.sample(n=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = []\n",
    "# for emotion in df_sample[\"emotion\"].unique():\n",
    "#     sample.append(\n",
    "#         {\n",
    "#             f\"{emotion}\": df_sample[df_sample[\"emotion\"] == emotion][\n",
    "#                 [\"text\", \"emotion\"]\n",
    "#             ].to_dict(orient=\"records\")\n",
    "#         }\n",
    "#     )\n",
    "# sample = sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample[\"anger\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\n",
      "<class 'str'>    1451778\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train[\"text\"].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+\", \"<url>\", text)\n",
    "    text = re.sub(\n",
    "        r\"(?:https?://|www\\.|:?//|:?//)[\\w-]+[\\.|/|\\?][\\w./?=&%#-]+\", \"<url>\", text\n",
    "    )\n",
    "    text = re.sub(r\"[\\w-]+\\.com(?:\\b|/)\", \"<url>\", text)\n",
    "    text = re.sub(r\"@\\S+\", \"<user>\", text)\n",
    "    # text = re.sub(r\"(<LH>\\s*)+\", \"<LH>\", text)\n",
    "    text = text.replace(\"<LH>\", \"<mask>\")\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = re.sub(r\"([!?.,;:])\\1+\", r\"\\1\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "df_train[\"text\"] = df_train[\"text\"].astype(str).apply(clean_text)\n",
    "if val:\n",
    "    df_val[\"text\"] = df_val[\"text\"].astype(str).apply(clean_text)\n",
    "df_test[\"text\"] = df_test[\"text\"].astype(str).apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\n",
      "<class 'str'>    1451778\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train[\"text\"].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with NaN values:\n",
      "Empty DataFrame\n",
      "Columns: [score, tweet_id, text, identification, emotion]\n",
      "Index: []\n",
      "Rows with empty text:\n",
      "Empty DataFrame\n",
      "Columns: [score, tweet_id, text, identification, emotion]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "nan_rows = df_train[df_train[\"text\"].isna()]\n",
    "print(\"Rows with NaN values:\")\n",
    "print(nan_rows)\n",
    "\n",
    "empty_rows = df_train[df_train[\"text\"].str.strip() == \"\"]\n",
    "print(\"Rows with empty text:\")\n",
    "print(empty_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna(subset=[\"text\"])\n",
    "if val:\n",
    "    df_val = df_val.dropna(subset=[\"text\"])\n",
    "df_test = df_test.dropna(subset=[\"text\"])\n",
    "\n",
    "df_train = df_train[df_train[\"text\"].str.strip() != \"\"]\n",
    "if val:\n",
    "    df_val = df_val[df_val[\"text\"].str.strip() != \"\"]\n",
    "df_test = df_test[df_test[\"text\"].str.strip() != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with NaN values:\n",
      "Empty DataFrame\n",
      "Columns: [score, tweet_id, text, identification, emotion]\n",
      "Index: []\n",
      "Rows with empty text:\n",
      "Empty DataFrame\n",
      "Columns: [score, tweet_id, text, identification, emotion]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "nan_rows = df_train[df_train[\"text\"].isna()]\n",
    "print(\"Rows with NaN values:\")\n",
    "print(nan_rows)\n",
    "\n",
    "empty_rows = df_train[df_train[\"text\"].str.strip() == \"\"]\n",
    "print(\"Rows with empty text:\")\n",
    "print(empty_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(df_train[\"emotion\"])\n",
    "\n",
    "df_train[\"label\"] = le.transform(df_train[\"emotion\"])\n",
    "if val:\n",
    "    df_val[\"label\"] = le.transform(df_val[\"emotion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(os.path.join(data_path, \"train.csv\"))\n",
    "if val:\n",
    "    df_val.to_csv(os.path.join(data_path, \"val.csv\"))\n",
    "df_test.to_csv(os.path.join(data_path, \"test.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "data_path = \"dataset/\"\n",
    "df_train = pd.read_csv(os.path.join(data_path, \"train.csv\"))\n",
    "df_val = pd.read_csv(os.path.join(data_path, \"val.csv\"))\n",
    "df_test = pd.read_csv(os.path.join(data_path, \"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "temp_model_name = \"FacebookAI/roberta-large\"\n",
    "\n",
    "if temp_model_name == model_name:\n",
    "    pass\n",
    "else:\n",
    "    model_name = temp_model_name\n",
    "    raise ValueError(\n",
    "        \"Model name mismatch, if you intended to change the model name, please rerun the cell\"\n",
    "    )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=\"cache/\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(df_train[\"label\"].unique()),\n",
    "    cache_dir=\"cache/\",\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "\n",
    "\n",
    "if lora:\n",
    "    lora_config = LoraConfig(\n",
    "        r=8,\n",
    "        lora_alpha=16,\n",
    "        task_type=TaskType.SEQ_CLS,\n",
    "    )\n",
    "    model = get_peft_model(model, lora_config)\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"lora\" not in name:\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the new special tokens\n",
    "special_tokens = {\"additional_special_tokens\": [\"<url>\", \"<user>\"]}\n",
    "\n",
    "# Add the special tokens to the tokenizer\n",
    "tokenizer.add_special_tokens(special_tokens)\n",
    "\n",
    "# Verify the new tokens\n",
    "print(\"Added tokens:\", tokenizer.additional_special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        super().__init__()\n",
    "        self.text = df[\"text\"].tolist()\n",
    "        self.labels = df[\"label\"].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\"text\": self.text[idx], \"label\": self.labels[idx]}\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    inputs = tokenizer(\n",
    "        [x[\"text\"] for x in batch],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = inputs.to(device)\n",
    "    labels = torch.tensor([x[\"label\"] for x in batch], dtype=torch.long)\n",
    "    labels = labels.to(device)\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class EmotionClassifier(torch.nn.Module):\n",
    "    def __init__(self, model, num_emotions=8):\n",
    "        super(EmotionClassifier, self).__init__()\n",
    "        self.model = model\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(768, num_emotions)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None):\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        logits = self.dropout(logits)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EmotionDataset(df_train)\n",
    "dl_train = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "if val:\n",
    "    validation_dataset = EmotionDataset(df_val)\n",
    "    dl_validation = DataLoader(\n",
    "        validation_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dl_train:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction=\"mean\"):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # Calculate the cross entropy loss for each instance\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction=\"none\")\n",
    "\n",
    "        # Compute the probability of the correct class (ground truth)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "\n",
    "        # Focal Loss computation\n",
    "        focal_loss = self.alpha * ((1 - pt) ** self.gamma) * ce_loss\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EmotionClassifier(model).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "\n",
    "if lora:\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Original total parameters: {total_params}\")\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Trainable parameters after LoRA: {trainable_params}\")\n",
    "\n",
    "if weighted_loss:\n",
    "    alpha = 0.5\n",
    "    gamma = 2\n",
    "    loss_fn = FocalLoss(alpha=alpha, gamma=gamma).to(device)\n",
    "else:\n",
    "    loss_fn = CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy,\n",
    "    MulticlassF1Score,\n",
    "    MulticlassPrecision,\n",
    "    MulticlassRecall,\n",
    ")\n",
    "\n",
    "# Initialize metrics (update num_classes based on your dataset)\n",
    "num_classes = len(\n",
    "    df_train[\"label\"].unique()\n",
    ")  # Replace with the number of emotion classes\n",
    "accuracy = MulticlassAccuracy(num_classes=num_classes).to(device)\n",
    "f1_score = MulticlassF1Score(num_classes=num_classes).to(device)\n",
    "precision = MulticlassPrecision(num_classes=num_classes).to(device)\n",
    "recall = MulticlassRecall(num_classes=num_classes).to(device)\n",
    "\n",
    "# Set up optimizer and learning rate scheduler with warm-up\n",
    "total_steps = len(dl_train) * epochs\n",
    "warmup_steps = int(warmup_proportion * total_steps)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Lists to store training and validation metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_f1_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "train_steps = []  # Keeps track of steps for plotting\n",
    "val_steps = []  # Keeps track of validation steps for plotting\n",
    "\n",
    "step = 0\n",
    "step_val = 0\n",
    "best_f1_score = 0.0  # Initialize to keep track of the best validation F1 score\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(dl_train, desc=f\"Epoch {epoch + 1}\")\n",
    "    i = 0\n",
    "    for batch in pbar:\n",
    "        # Extract inputs and labels from batch\n",
    "        inputs, labels = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Update metrics\n",
    "        predictions = torch.argmax(outputs, dim=-1)\n",
    "        accuracy.update(predictions, labels)\n",
    "        f1_score.update(predictions, labels)\n",
    "        precision.update(predictions, labels)\n",
    "        recall.update(predictions, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        if step % 5000 == 0:\n",
    "            train_steps.append(step)\n",
    "            train_losses.append(loss.item())\n",
    "            train_accuracies.append(accuracy.compute().item())\n",
    "            train_f1_scores.append(f1_score.compute().item())\n",
    "\n",
    "        # Display progress\n",
    "        pbar.set_postfix({\"loss\": total_loss / (i + 1)})\n",
    "\n",
    "        step += 1\n",
    "        i += 1\n",
    "\n",
    "    print(f\"Training loss: {total_loss / len(dl_train)}\")\n",
    "    print(f\"Training Accuracy: {train_accuracies[-1]}\")\n",
    "    print(f\"Training F1 Score: {train_f1_scores[-1]}\")\n",
    "    print(f\"Training Precision: {precision.compute().item()}\")\n",
    "    print(f\"Training Recall: {recall.compute().item()}\")\n",
    "\n",
    "    # Reset metrics for next epoch\n",
    "    accuracy.reset()\n",
    "    f1_score.reset()\n",
    "    precision.reset()\n",
    "    recall.reset()\n",
    "\n",
    "    torch.save(model, f\"model/model_epoch_{epoch+1}.ckpt\")\n",
    "\n",
    "    if val:\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        pbar = tqdm(dl_validation, desc=f\"Epoch {epoch + 1} Validation\")\n",
    "        with torch.no_grad():\n",
    "            for batch in pbar:\n",
    "                inputs, labels = batch\n",
    "\n",
    "                outputs = model(**inputs)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                # Update metrics\n",
    "                predictions = torch.argmax(outputs, dim=-1)\n",
    "                accuracy.update(predictions, labels)\n",
    "                f1_score.update(predictions, labels)\n",
    "                precision.update(predictions, labels)\n",
    "                recall.update(predictions, labels)\n",
    "\n",
    "                if step_val % 5000 == 0:\n",
    "                    val_steps.append(step_val / val_size)\n",
    "                    val_losses.append(loss.item())\n",
    "                    val_accuracies.append(accuracy.compute().item())\n",
    "                    val_f1_scores.append(f1_score.compute().item())\n",
    "\n",
    "                step_val += 1\n",
    "\n",
    "        print(f\"Validation loss: {total_loss / len(dl_validation)}\")\n",
    "        print(f\"Validation Accuracy: {val_accuracies[-1]}\")\n",
    "        print(f\"Validation F1 Score: {val_f1_scores[-1]}\")\n",
    "        print(f\"Validation Precision: {precision.compute().item()}\")\n",
    "        print(f\"Validation Recall: {recall.compute().item()}\")\n",
    "\n",
    "        # Early stopping mechanism\n",
    "        if epoch == 0:\n",
    "            best_loss = total_loss\n",
    "            best_f1_score = val_f1_scores[-1]\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            if total_loss < best_loss or val_f1_scores[-1] > best_f1_score:\n",
    "                # Save model checkpoint if validation metrics improve\n",
    "                best_loss = min(best_loss, total_loss)\n",
    "                best_f1_score = max(best_f1_score, val_f1_scores[-1])\n",
    "                patience_counter = 0\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"model_state_dict\": model.state_dict(),\n",
    "                        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    },\n",
    "                    f\"model/checkpoint{epoch+1}.pth\",\n",
    "                )\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter == patience:\n",
    "                    print(\"Early stopping\")\n",
    "                    break\n",
    "\n",
    "        # Reset metrics for next epoch\n",
    "        accuracy.reset()\n",
    "        f1_score.reset()\n",
    "        precision.reset()\n",
    "        recall.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the metrics\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(train_steps, train_losses, label=\"Training Loss\")\n",
    "if val:\n",
    "    plt.plot(val_steps, val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Plot training and validation accuracy and F1 score on the same chart\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(train_steps, train_accuracies, label=\"Training Accuracy\", linestyle=\"-\")\n",
    "plt.plot(train_steps, train_f1_scores, label=\"Training F1 Score\", linestyle=\"--\")\n",
    "if val:\n",
    "    plt.plot(val_steps, val_accuracies, label=\"Validation Accuracy\", linestyle=\"-\")\n",
    "    plt.plot(val_steps, val_f1_scores, label=\"Validation F1 Score\", linestyle=\"--\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Training and Validation Accuracy & F1 Score\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = \"model/model_epoch_5_BFN.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class TestEmotionDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        super().__init__()\n",
    "        self.text = df[\"text\"].tolist()\n",
    "        self.id = df[\"tweet_id\"].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\"text\": self.text[idx], \"id\": self.id[idx]}\n",
    "        return item\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    inputs = tokenizer(\n",
    "        [x[\"text\"] for x in batch], return_tensors=\"pt\", padding=True, truncation=True\n",
    "    )\n",
    "    inputs = inputs.to(device)\n",
    "    ids = [x[\"id\"] for x in batch]\n",
    "    return inputs, ids\n",
    "\n",
    "\n",
    "test_dataset = TestEmotionDataset(df_test)\n",
    "dl_test = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3447/1013053347.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(load_model, map_location=device).to(device)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.load(load_model, map_location=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12875/12875 [06:42<00:00, 32.01it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    tweet_ids = []\n",
    "    emotion = []\n",
    "    pbar = tqdm(dl_test, desc=\"Predicting\")\n",
    "    for inputs, ids in pbar:\n",
    "        logits = model(**inputs)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        tweet_ids.extend(ids)\n",
    "        emotion.extend(preds.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(df_train[\"emotion\"])\n",
    "\n",
    "emotion = le.inverse_transform(emotion)\n",
    "submit = pd.DataFrame({\"id\": tweet_ids, \"emotion\": emotion})\n",
    "submit.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x218443</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x26289a</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x31c6e0</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0x32edee</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0x3714ee</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0x235628</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0x283024</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id       emotion\n",
       "0  0x28b412  anticipation\n",
       "1  0x2de201         trust\n",
       "2  0x218443           joy\n",
       "3  0x2939d5  anticipation\n",
       "4  0x26289a  anticipation\n",
       "5  0x31c6e0      surprise\n",
       "6  0x32edee       sadness\n",
       "7  0x3714ee         anger\n",
       "8  0x235628           joy\n",
       "9  0x283024       sadness"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Below are the models I experimented with for fine-tuning:\n",
    "\n",
    "1. **BERT-base-uncased**\n",
    "2. **BERT-base-cased**\n",
    "3. **BERT-large-uncased**\n",
    "4. **ROBERTA-base**\n",
    "5. **ROBERTA-large**\n",
    "6. **twitter-roberta-base-emotion-multilabel-latest**\n",
    "7. **cardiffnlp/twitter-roberta-base-sentiment-latest**\n",
    "8. **T5-large** *(failed)*\n",
    "\n",
    "Among these, **ROBERTA-large** yielded the best results in my experience.\n",
    "\n",
    "### Parameter Setting\n",
    "\n",
    "Due to the lengthy time required for fine-tuning, I couldn't perform detailed hyperparameter tuning. The final parameter settings were based on a combination of suggestions from GPT and my personal experience.\n",
    "\n",
    "### Overfitting\n",
    "\n",
    "Initially, I focused on mitigating overfitting during the fine-tuning process, assuming it was crucial for better performance. Techniques applied included:\n",
    "\n",
    "- Learning rate scheduling\n",
    "- Warm-up steps\n",
    "- Weight decay\n",
    "- Dropout layers\n",
    "\n",
    "However, overfitting still consistently occurred around **epoch 5**. I concluded that, given the nature of the dataset, overfitting might be unavoidable despite these measures.\n",
    "\n",
    "---\n",
    "\n",
    "## Preprocessing\n",
    "\n",
    "Deciding on how to clean the data presented the most challenges. The main options were whether to **delete**, **retain**, or **convert into special tokens**. Given the vast number of combinations, I initially considered sampling to test performance. However, since analyzing only a portion of the data could introduce additional confounding factors, I adopted a decision-tree approach to refine choices iteratively until reaching the optimal setup.\n",
    "\n",
    "### Preprocessing Steps\n",
    "\n",
    "1. **Delete duplicates**\n",
    "2. **Remove empty entries**\n",
    "3. **Convert URLs into `<url>` tokens**\n",
    "4. **Convert `<LH>` into `<mask>` tokens**\n",
    "5. **Convert usernames into `<user>` tokens**\n",
    "6. **Reduce multiple punctuation marks to a single one**\n",
    "7. **Reduce multiple spaces to a single space**\n",
    "\n",
    "### Mask Token\n",
    "\n",
    "Replacing the `<LH>` token with `<mask>` initially seemed counterintuitive since the model was being used for sequence classification rather than fill-mask tasks. However, I hypothesized that since the original model was trained with `<mask>` tokens, this approach might reduce noise. Surprisingly, this change improved performance by about **1%**.\n",
    "\n",
    "Later, I discovered that the `<LH>` token functions as a cloze-style placeholder. Toward the end of my experimentation, I attempted to use a Twitter fine-tuned BERT-large fill-mask model to reconstruct the missing parts, but time constraints prevented me from completing the fine-tuning process or conducting deeper analyses. This aspect requires further exploration.\n",
    "\n",
    "### Special Tokens\n",
    "\n",
    "Initially, I removed URLs and usernames, considering them noise. However, upon analyzing the preprocessed dataset, I observed that deleting these elements made the sentences semantically awkward. Retaining and replacing these elements with special tokens resulted in a noticeable improvement in the final scores, confirming their relevance to the task.\n",
    "\n",
    "---\n",
    "\n",
    "## Balancing\n",
    "\n",
    "The training dataset provided is extremely unbalanced, with the \"joy\" class containing about 40% of the total dataset. To address this issue, I experimented with several methods:\n",
    "\n",
    "### SMOTE\n",
    "\n",
    "The first approach I tried was **SMOTE (Synthetic Minority Oversampling Technique)** to generate additional data and balance the dataset. However, this method was extremely time-consuming, and I was uncertain whether SMOTE could effectively work with BERT-like embeddings. \n",
    "\n",
    "### Undersampling and Oversampling\n",
    "\n",
    "1. **Simple Undersampling and Oversampling**  \n",
    "   I attempted to balance the dataset by:\n",
    "   - **Undersampling:** Reducing the size of overrepresented classes.\n",
    "   - **Oversampling:** Duplicating instances in underrepresented classes.  \n",
    "\n",
    "   Unfortunately, this resulted in significant performance degradation. The duplicated data led to overfitting, and the model performance dropped sharply.\n",
    "\n",
    "2. **Partial Undersampling of the \"joy\" Class**  \n",
    "   I tried reducing the \"joy\" class to 60% of its original size to make the dataset more balanced. However, this also caused a performance downgrade.\n",
    "\n",
    "### Ollama Oversampling\n",
    "\n",
    "Another method I explored was using **LLaMA** to generate synthetic data for underrepresented classes. However:\n",
    "- Generating sufficient data for each class (excluding \"joy\") required approximately 20 hours per class.\n",
    "- The randomness in model generation led to some unexpected and irrelevant outputs.\n",
    "- My past experiences with generative models in competitions (e.g., AI-CUP) created skepticism about the reliability of this approach.\n",
    "\n",
    "Due to these issues, I found this method to be impractical.\n",
    "\n",
    "### Training-Level Balancing - Weighted Loss\n",
    "\n",
    "#### 1. Multilevel Weighted Loss  \n",
    "   I assigned weights to the loss function by multiplying the loss for each class with its relative size fraction.  \n",
    "   **Outcome:** This method significantly downgraded performance, likely due to improper weight balancing.\n",
    "\n",
    "#### 2. Focal Loss  \n",
    "   Focal loss is designed to address imbalanced datasets by focusing more on hard-to-classify examples. While it slightly decreased performance overall, it provided the following benefits:\n",
    "   - Better synchronization between F1 score and loss.\n",
    "   - Reduced overfitting. (Without focal loss, the highest F1 score often coincided with the early stages of overfitting.)\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Despite the severe class imbalance in the dataset, none of the balancing methods tested yielded significant performance improvements. The optimal model I ultimately used did not apply any balancing techniques.  \n",
    "\n",
    "Further exploration into advanced data augmentation or novel loss functions might be needed to effectively address this challenge.\n",
    "\n",
    "---\n",
    "\n",
    "## Others\n",
    "\n",
    "### PCA and t-SNE Analysis\n",
    "\n",
    "To better understand the embeddings, I experimented with **PCA** and **t-SNE** visualizations. These methods provided insights into the data distribution and class separability. However, I avoided including this analysis in the main codebase as it would unnecessarily complicate the implementation. It remained an exploratory step for understanding the data and model behavior.\n",
    "\n",
    "### Mask Handling\n",
    "\n",
    "When working with `<mask>` tokens in the dataset, I identified some improvements that could potentially enhance the quality of the data and model performance:\n",
    "\n",
    "1. **Cleaning Excessive `<mask>` Tokens**  \n",
    "   - In the training dataset, some examples contained an excessive number of `<mask>` tokens, with the highest being up to 18.  \n",
    "   - Removing such examples could make the dataset cleaner and less noisy.\n",
    "\n",
    "2. **Improving the Mask Filling Strategy**  \n",
    "   - **Current Approach:**  \n",
    "     - Fill `<mask>` tokens one by one with the highest-scoring prediction, regardless of the score.  \n",
    "     - This approach may introduce low-confidence predictions into the data.  \n",
    "   - **Proposed Enhancement:**  \n",
    "     - Only fill `<mask>` tokens if the model's confidence score exceeds a threshold (e.g., 0.7).  \n",
    "     - This would ensure higher-quality and more reliable mask replacements.  \n",
    "   \n",
    "3. **Appended Emotion Tags**  \n",
    "   - During the training data filling process, I appended the corresponding emotion to the end of each text in the format:  \n",
    "     `(emotion: {emotion})`.  \n",
    "   - While attention mechanisms work in complex and sometimes unintuitive ways, testing revealed that this modification made the mask-filling process slightly more stable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
