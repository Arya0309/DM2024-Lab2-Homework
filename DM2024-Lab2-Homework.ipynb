{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name:\n",
    "\n",
    "Student ID:\n",
    "\n",
    "GitHub ID:\n",
    "\n",
    "Kaggle name:\n",
    "\n",
    "Kaggle private scoreboard snapshot:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home exercises** in the [DM2024-Lab2-master Repo](https://github.com/didiersalazar/DM2024-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework) regarding Emotion Recognition on Twitter by this link: https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)**. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developing the model for the competition (You can use code and comment on it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_path = \"dataset/\"\n",
    "df_data = pd.read_json(os.path.join(data_path, \"tweets_DM.json\"), lines=True)\n",
    "df_data[\"_source\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source = pd.json_normalize(df_data[\"_source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.concat([df_data, df_source], axis=1)\n",
    "df_data = df_data.drop(columns=[\"_source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_data[\"tweet.hashtags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data.rename(columns={\"tweet.hashtags\": \"hashtags\"})\n",
    "df_data = df_data.rename(columns={\"tweet.tweet_id\": \"tweet_id\"})\n",
    "df_data = df_data.rename(columns={\"tweet.text\": \"text\"})\n",
    "df_data = df_data.rename(columns={\"_score\": \"score\"})\n",
    "df_data = df_data.rename(columns={\"_index\": \"index\"})\n",
    "df_data = df_data.rename(columns={\"_crawldate\": \"crawldate\"})\n",
    "df_data = df_data.rename(columns={\"_type\": \"type\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_identification = pd.read_csv(os.path.join(data_path, \"data_identification.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.merge(df_data, df_identification, on=\"tweet_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_data[df_data[\"identification\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotion = pd.read_csv(os.path.join(data_path, \"emotion.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.merge(df_data, df_emotion, on=\"tweet_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_data[df_data[\"identification\"] == \"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_list = []\n",
    "for i in range(len(df_train)):\n",
    "    if df_train[\"emotion\"][i] not in emotion_list:\n",
    "        emotion_list.append(df_train[\"emotion\"][i])\n",
    "print(emotion_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_list.append(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_id = {}\n",
    "id_emotion = {}\n",
    "for i in range(len(emotion_list)):\n",
    "    emotion_id[emotion_list[i]] = i\n",
    "print(emotion_id)\n",
    "\n",
    "for i in range(len(emotion_list)):\n",
    "    id_emotion[i] = emotion_list[i]\n",
    "print(id_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"emotion_id\"] = df_train[\"emotion\"].apply(lambda x: emotion_id[x])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"emotion\"] = \"None\"\n",
    "df_test[\"emotion_id\"] = df_test[\"emotion\"].apply(lambda x: emotion_id[x])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "df_val = df_train.sample(frac=0.2)\n",
    "df_train = df_train.drop(df_val.index)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df(df, file_path):\n",
    "    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(df_train, \"train.csv\")\n",
    "save_df(df_val, \"val.csv\")\n",
    "save_df(df_test, \"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def load_df(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "data_path = \"dataset/\"\n",
    "df_train = load_df(os.path.join(data_path, \"train.csv\"))\n",
    "df_val = load_df(os.path.join(data_path, \"val.csv\"))\n",
    "df_test = load_df(os.path.join(data_path, \"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Begin Assignment Here\n",
    "lr = 1e-5\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "grad_clip = 1.0\n",
    "bert = \"google-bert/bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(bert, cache_dir=\"cache/\")\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    bert, num_labels=len(df_train[\"emotion_id\"].unique()), cache_dir=\"cache/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        # Use the provided dataframe\n",
    "        self.data = dataframe[[\"text\", \"emotion_id\"]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, int):\n",
    "            # Tokenize the text\n",
    "            tokenized_text = tokenizer(\n",
    "                self.data.iloc[idx][\"text\"],\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            sample = {\n",
    "                \"input_ids\": tokenized_text[\"input_ids\"].squeeze(0),\n",
    "                \"attention_mask\": tokenized_text[\"attention_mask\"].squeeze(0),\n",
    "                \"emotion_id\": torch.tensor(\n",
    "                    self.data.iloc[idx][\"emotion_id\"], dtype=torch.long\n",
    "                ),\n",
    "            }\n",
    "            return sample\n",
    "        else:\n",
    "            raise TypeError(\"Index must be an integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_ids = [item[\"input_ids\"] for item in batch]\n",
    "    attention_mask = [item[\"attention_mask\"] for item in batch]\n",
    "    emotion_ids = [item[\"emotion_id\"] for item in batch]\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": torch.stack(input_ids),\n",
    "        \"attention_mask\": torch.stack(attention_mask),\n",
    "        \"emotion_id\": torch.tensor(emotion_ids),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EmotionDataset(df_train)\n",
    "dl_train = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "validation_dataset = EmotionDataset(df_val)\n",
    "dl_validation = DataLoader(\n",
    "    validation_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn\n",
    ")\n",
    "test_dataset = EmotionDataset(df_test)\n",
    "dl_test = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dl_train:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class EmotionClassifier(torch.nn.Module):\n",
    "    def __init__(self, model, num_emotions=8):\n",
    "        super(EmotionClassifier, self).__init__()\n",
    "        self.model = model\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(768, num_emotions)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        logits = self.dropout(logits)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EmotionClassifier(model).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "loss_fn = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_emotion = {\n",
    "    0: \"anticipation\",\n",
    "    1: \"sadness\",\n",
    "    2: \"fear\",\n",
    "    3: \"joy\",\n",
    "    4: \"anger\",\n",
    "    5: \"trust\",\n",
    "    6: \"disgust\",\n",
    "    7: \"surprise\",\n",
    "    8: \"None\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy,\n",
    "    MulticlassF1Score,\n",
    "    MulticlassPrecision,\n",
    "    MulticlassRecall,\n",
    ")\n",
    "\n",
    "# Initialize metrics (update num_classes based on your dataset)\n",
    "num_classes = len(id_emotion)  # Replace with the number of emotion classes\n",
    "accuracy = MulticlassAccuracy(num_classes=num_classes).to(device)\n",
    "f1_score = MulticlassF1Score(num_classes=num_classes).to(device)\n",
    "precision = MulticlassPrecision(num_classes=num_classes).to(device)\n",
    "recall = MulticlassRecall(num_classes=num_classes).to(device)\n",
    "\n",
    "# Set up optimizer and learning rate scheduler with warm-up\n",
    "total_steps = len(dl_train) * epochs\n",
    "warmup_steps = int(0.1 * total_steps)  # Warm-up for 10% of total steps\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(dl_train, desc=f\"Epoch {epoch + 1}\")\n",
    "    for batch in pbar:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        emotion_id = batch[\"emotion_id\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        loss = loss_fn(outputs, emotion_id)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Update metrics\n",
    "        predictions = torch.argmax(outputs, dim=-1)\n",
    "        accuracy.update(predictions, emotion_id)\n",
    "        f1_score.update(predictions, emotion_id)\n",
    "        precision.update(predictions, emotion_id)\n",
    "        recall.update(predictions, emotion_id)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        pbar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "    print(f\"Training loss: {total_loss / len(dl_train)}\")\n",
    "    print(f\"Training Accuracy: {accuracy.compute().item()}\")\n",
    "    print(f\"Training F1 Score: {f1_score.compute().item()}\")\n",
    "    print(f\"Training Precision: {precision.compute().item()}\")\n",
    "    print(f\"Training Recall: {recall.compute().item()}\")\n",
    "\n",
    "    # Reset metrics\n",
    "    accuracy.reset()\n",
    "    f1_score.reset()\n",
    "    precision.reset()\n",
    "    recall.reset()\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(dl_validation, desc=f\"Epoch {epoch + 1} Validation\")\n",
    "    with torch.no_grad():\n",
    "        for batch in pbar:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            emotion_id = batch[\"emotion_id\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            loss = loss_fn(outputs, emotion_id)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Update metrics\n",
    "            predictions = torch.argmax(outputs, dim=-1)\n",
    "            accuracy.update(predictions, emotion_id)\n",
    "            f1_score.update(predictions, emotion_id)\n",
    "            precision.update(predictions, emotion_id)\n",
    "            recall.update(predictions, emotion_id)\n",
    "\n",
    "    print(f\"Validation loss: {total_loss / len(dl_validation)}\")\n",
    "    print(f\"Validation Accuracy: {accuracy.compute().item()}\")\n",
    "    print(f\"Validation F1 Score: {f1_score.compute().item()}\")\n",
    "    print(f\"Validation Precision: {precision.compute().item()}\")\n",
    "    print(f\"Validation Recall: {recall.compute().item()}\")\n",
    "\n",
    "    # Reset metrics\n",
    "    accuracy.reset()\n",
    "    f1_score.reset()\n",
    "    precision.reset()\n",
    "    recall.reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
